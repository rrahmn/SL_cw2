{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy import transpose\n",
    "from numpy.linalg import inv\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(0)\n",
    "from numpy import genfromtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading in data\n",
    "zipcombo = np.array(genfromtxt('zipcombo.dat.txt'))     #full data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals, freq = np.unique(zipcombo[:,0], return_counts=True)\n",
    "plt.bar(vals, freq)\n",
    "plt.xticks(np.arange(0, 10, 1))\n",
    "plt.savefig('Q1_1.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def OneVersusRest(data, classes):\n",
    "    \"\"\" function to transform data labels into -1,1 where 1 is class k and -1 is rest \n",
    "    input: original labels\n",
    "    output: transformed labels in rows=NumberOfDataPoints by columns=NumberOfClasses dimensional array so that each column k has labels +1 if th original label was k or -1 else\"\"\"\n",
    "    original_labels = data[:,[0]]\n",
    "    NumberOfDataPoints = data.shape[0]\n",
    "    NumberOfClasses = classes.shape[1]\n",
    "    transformed_labels = np.zeros((NumberOfDataPoints, NumberOfClasses))\n",
    "\n",
    "    for i in range(NumberOfClasses):\n",
    "        k = classes[0,i]\n",
    "        transformed_labels[:,i] = 2*(original_labels[:,0]==k) - 1\n",
    "    return transformed_labels\n",
    "\n",
    "def Poly_kernel_matrix(x,y,d):\n",
    "    \"\"\" function to compute gram matrix for polynomial kernel with power d=1. Using the first power we can then iteratively multiply the gram matrix with itself to build higher powers of it. \"\"\"\n",
    "    data1 = x.copy()\n",
    "    data2 = y.copy()\n",
    "    data1 = data1[:,1:] #getting rid of label column\n",
    "    data2 = data2[:,1:] #getting rid of label column\n",
    "    K = (data1@ np.transpose(data2))\n",
    "    return K\n",
    "\n",
    "\n",
    "\n",
    "def test_one_versus_rest(testlabels,classes,powers, alpha, kernelmatrix):\n",
    "    \"\"\" testing function for one versus rest with polynomial kernel\n",
    "    inputs:\n",
    "        testlabels: the ground truth labels of the testing data\n",
    "        classes: the possible classes of our data \n",
    "        powers: the powers that we want to pass to polynomial kernel\n",
    "        alpha: the alpha values found by the training algorithm\n",
    "        kernelmatrix: the gram matrix with rows corresponding to our training data and columns corresponding to testing data\n",
    "        \n",
    "        outputs:\n",
    "            \n",
    "            confidence: the (NumberOfPowers by NumberOfClasses by NumberOfDataPoints) 3D-dimensional array containing \n",
    "            the confidences of each of our 10(=NumberOfClasses) OVR classifiers trained on the training data with polynomial kernel power=d (for d=1 to NumberOfPowers) tested on a \n",
    "            test set with size=NumberOfDataPoints. \n",
    "            prediction: the (NumberOfPowers by NumberOfDataPoints) array containing the predicted label which is found by taking the confidence array and taking argmax of the confidence array across \n",
    "            second dimension of the array (ie across NumberOfClasses). This finds the indices(or labels) that maximise the confidence\n",
    "            accuracy: the (1 by NumberOfPowers) dimensional accuracies of our predictions. Found by checking the prediction array against the ground truth labels\"\"\"\n",
    "    testing_data = testlabels.copy()\n",
    "    \n",
    "    K1 = kernelmatrix\n",
    "\n",
    "    NumberOfClasses = classes.shape[1]\n",
    "    NumberOfDataPoints = testing_data.shape[0]\n",
    "    NumberOfPowers = powers.shape[1]\n",
    "    confidence = np.zeros((NumberOfPowers,NumberOfClasses,NumberOfDataPoints))\n",
    "    predictions = np.zeros((NumberOfPowers,NumberOfDataPoints))\n",
    "    counter = np.zeros((NumberOfPowers,NumberOfDataPoints))\n",
    "\n",
    "    currK=1\n",
    "    for d in range(NumberOfPowers):\n",
    "        currK = currK*K1 #mutiplying gram matrix with itself to find powers of gram matrix iteratively\n",
    "        for t in range(NumberOfDataPoints):\n",
    "            y_t = testing_data[[t],0] #receive label\n",
    "\n",
    "            confidence[d,:,[t]] = (np.matmul(alpha[d,:,:],currK[:, [t]])).T #computing confidence\n",
    "            predictions[d,[t]] = np.argmax(confidence[d,:,[t]], axis=1)  #predict by argmaxing to find indices that maximise confidence\n",
    "            y_hat = predictions[d,[t]]\n",
    "            \n",
    "            #if correct prediction\n",
    "            counter[d,[t]] = 1*((y_hat  == y_t))\n",
    "\n",
    "        \n",
    "    accuracy = 100*np.sum(counter,axis=1)/NumberOfDataPoints\n",
    "    return accuracy, confidence, predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train_one_versus_rest(traininglabels,classes,powers, EPOCHS,kernelmatrix):\n",
    "    \"\"\"\n",
    "    function to train NumberOfClasses ovr classifiers in parallel\n",
    "    INPUT\n",
    "     data: training data's original labels \n",
    "     classes: labels we want to classify the data to\n",
    "     powers: powers we're passing to our kernel function\n",
    "     EPOCHS: is the number of times we cycle through data\n",
    "    kernelmatrix: the gram matrix with rows corresponding to our training data and columns also corresponding to training data\n",
    "\n",
    "     OUTPUT\n",
    "     alpha: the final alpha values after the training has finished\n",
    "     it is (NumberOfPowers by NumberOfClasses by NumberOfDataPoints) dimensional\n",
    "    \"\"\"\n",
    "    training_data = traininglabels.copy()\n",
    "    k_class_train = OneVersusRest(training_data,classes)\n",
    "    K1 = kernelmatrix\n",
    "\n",
    "\n",
    "    \n",
    "    NumberOfClasses = classes.shape[1]\n",
    "    NumberOfDataPoints = training_data.shape[0]\n",
    "    NumberOfPowers = powers.shape[1]\n",
    "    #initialise alpha vector to zeros\n",
    "    alpha = np.zeros((NumberOfPowers,NumberOfClasses,NumberOfDataPoints))\n",
    "    currK=1\n",
    "    for epoch in range(EPOCHS):\n",
    "        currK=1\n",
    "        for d in range(NumberOfPowers):\n",
    "            currK = currK*K1 #gram matrix power\n",
    "            for t in range(NumberOfDataPoints):\n",
    "                y_t = k_class_train[[t],:] #receive labels in OVR form\n",
    "\n",
    "                #prediction step\n",
    "                y_hat = np.sign(np.matmul(alpha[d,:,:],currK[:, [t]])) \n",
    "                y_hat = np.squeeze(y_hat)\n",
    "                #training step\n",
    "                alpha[d,:,t] = alpha[d,:,t] + y_t*((y_hat != y_t)) #update alpha only if prediction wrong\n",
    "\n",
    "    return alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Results: Perform 20 runs for d = 1, . . . , 7 each run should randomly split zipcombo into 80%\n",
    "train and 20% test. Report the mean test and train error rates as well as well as standard deviations.\n",
    "Thus your data table, here, will be 2 × 7 with each “cell” containing a mean±std.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we compute the full polynomial kernel gram matrix so that we don't have to recompute the same values and just extract the rows and columns we need\n",
    "full_ker_poly  = Poly_kernel_matrix(zipcombo,zipcombo,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this code cell takes about 4 minutes to run\n",
    "MAXRUNS=20\n",
    "powers=np.array([[1,2,3,4,5,6,7]])\n",
    "full_data = zipcombo.copy()\n",
    "labelsdata = full_data[:,[0]] #extract the labels\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "NUMPOWERS = powers.shape[1]\n",
    "epochs=2\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "indicesFullData = np.arange(full_data.shape[0]) #we will keep track of the indices of the data so that we can extract the right rows and columns from full polynomial kernel fram matrix\n",
    "\n",
    "\n",
    "#arrays to store accuracies\n",
    "all_training_accuracies = np.zeros((MAXRUNS, NUMPOWERS))\n",
    "all_testing_accuracies = np.zeros((MAXRUNS, NUMPOWERS))\n",
    "\n",
    "for runs in range(MAXRUNS):\n",
    "    rng.shuffle(indicesFullData, axis=0) #shuffle indices\n",
    "    splits=np.array_split(labelsdata[indicesFullData,[0]],5) #5 splits for training and testing separation\n",
    "    training_data =np.array([np.hstack(splits[:4])]).T #4/5 parts or 80% as training split\n",
    "    testing_data = np.array([splits[4]]).T #1/5 parts or 20% as testing split\n",
    "\n",
    "    #split indices into training and testing indices    \n",
    "    indexsplit = np.array_split(indicesFullData,5)\n",
    "    indextrain = np.concatenate((indexsplit[0], indexsplit[1],indexsplit[2],indexsplit[3]))\n",
    "    indextest = indexsplit[4]\n",
    "\n",
    "    #extraxt training and testing kernels from full gram matrix by using the corresponding indices\n",
    "    trainingkernel = full_ker_poly[indextrain,][:,indextrain]\n",
    "    testingkernel = full_ker_poly[indextrain,][:,indextest]\n",
    "\n",
    "    alpha = train_one_versus_rest(training_data,classes,powers,epochs,trainingkernel) #training and returning alpha\n",
    "    training_acc, training_conf, train_predictions = test_one_versus_rest(training_data,classes,powers, alpha,trainingkernel) #training accuracies\n",
    "    testing_acc, testing_conf, test_predictions = test_one_versus_rest(testing_data,classes,powers, alpha,testingkernel) #testing accuracies\n",
    "\n",
    "    all_training_accuracies[runs,:] = training_acc  #storing accuracies\n",
    "    all_testing_accuracies[runs,:] = testing_acc    #storing accuracies\n",
    "\n",
    "    #storing predictions so that we can take out the optimal predictions out later after we crossvalidate to find optimal d values\n",
    "    if(runs==0):\n",
    "        test_predictions_store = test_predictions\n",
    "        train_predictions_store = train_predictions\n",
    "    else:\n",
    "        test_predictions_store = np.dstack((test_predictions_store,test_predictions))\n",
    "        train_predictions_store = np.dstack((train_predictions_store,train_predictions))\n",
    "\n",
    "#transposing arrays for a nicer form to work with\n",
    "test_predictions_store = np.transpose(test_predictions_store,(2,0,1))\n",
    "train_predictions_store = np.transpose(train_predictions_store,(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>ONE VERSUS REST multiclass prediction<<<\n",
      "training errors(mean±std):\n",
      "8.97±1.4       2.12±0.55       0.79±0.13       0.49±0.13       0.38±0.25       0.24±0.09       0.21±0.06       \n",
      "testing errors(mean±std):\n",
      "10.52±1.45     4.82±0.64     3.6±0.39     3.5±0.52     3.21±0.41     3.18±0.4     3.19±0.46     "
     ]
    }
   ],
   "source": [
    "test_errors  = 100 - all_testing_accuracies\n",
    "train_errors  = 100 - all_training_accuracies\n",
    "print('>>>ONE VERSUS REST multiclass prediction<<<')\n",
    "print('training errors(mean±std):')\n",
    "for d in range(NUMPOWERS):\n",
    "    print(str(round(np.mean(train_errors, axis=0)[d],2)) + \"±\" +  str(round(np.std(train_errors, axis=0)[d],2)),  end='       ')\n",
    "print('\\ntesting errors(mean±std):')\n",
    "for d in range(NUMPOWERS):\n",
    "    print(str(round(np.mean(test_errors, axis=0)[d],2)) + \"±\" +  str(round(np.std(test_errors, axis=0)[d],2)),  end='     ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Cross-validation: Perform 20 runs : when using the 80% training data split from within to perform\n",
    "5-fold cross-validation to select the “best” parameter d\n",
    "∗\n",
    "then retrain on full 80% training set using\n",
    "d\n",
    "∗ and then record the test errors on the remaining 20%. Thus you will find 20 d\n",
    "∗ and 20 test errors.\n",
    "Your final result will consist of a mean test error±std and a mean d\n",
    "∗ with std."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riand\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    }
   ],
   "source": [
    "#this code cell takes about 11 minutes to run\n",
    "MAXRUNS=20\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "powers=np.array([[1,2,3,4,5,6,7]])\n",
    "NUMPOWERS = powers.shape[1]\n",
    "epochs=2\n",
    "full_data = zipcombo.copy()\n",
    "labelsdata = full_data[:,[0]]\n",
    "indicesFullData = np.arange(full_data.shape[0])\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "optimal_d = np.zeros((MAXRUNS,1))\n",
    "\n",
    "for runs in range(MAXRUNS):\n",
    "    rng.shuffle(indicesFullData, axis=0)#shuffle indices\n",
    "    splits=np.array_split(labelsdata[indicesFullData,[0]],5) #5 splits for training and testing separation\n",
    "    training_data =np.array([np.hstack(splits[:4])]).T #4/5 parts or 80% as training split\n",
    "    testing_data = np.array([splits[4]]).T #1/5 parts or 20% as testing split\n",
    "    \n",
    "    #split indices into training and testing indices\n",
    "    indexsplit = np.array_split(indicesFullData,5)\n",
    "    indextrain = np.concatenate((indexsplit[0], indexsplit[1],indexsplit[2],indexsplit[3]))\n",
    "    indextest = indexsplit[4]\n",
    "\n",
    "    #cross validation to find optimal d\n",
    "    cross_splits = np.array_split(training_data,5)\n",
    "    cross_splits_indices = np.array_split(indextrain,5)\n",
    "    accuracies_sum=0\n",
    "    for fold_number in range(5):\n",
    "        training_folds = np.vstack(np.delete(cross_splits, fold_number))\n",
    "        training_folds_indices = np.hstack(np.delete(cross_splits_indices, fold_number))\n",
    "        trainingkernel = full_ker_poly[training_folds_indices,:][:,training_folds_indices]\n",
    "\n",
    "        #training and testing over cross validation folds\n",
    "        alpha = train_one_versus_rest(training_folds,classes,powers,epochs,trainingkernel) #training and returning alpha\n",
    "        training_acc, training_conf, train_predictions = test_one_versus_rest(training_folds,classes,powers, alpha,trainingkernel) #training accuracies\n",
    "        accuracies_sum = accuracies_sum + training_acc\n",
    "    optimal_d[runs,0] = np.argmax(accuracies_sum, axis=0) #find optimal d* by finding d maximising the cross validation accuracies\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run:1, optimal d:7, associated test error:3.228\n",
      "run:2, optimal d:7, associated test error:3.55\n",
      "run:3, optimal d:6, associated test error:2.905\n",
      "run:4, optimal d:7, associated test error:3.873\n",
      "run:5, optimal d:7, associated test error:3.228\n",
      "run:6, optimal d:6, associated test error:2.582\n",
      "run:7, optimal d:6, associated test error:3.12\n",
      "run:8, optimal d:6, associated test error:3.497\n",
      "run:9, optimal d:7, associated test error:2.636\n",
      "run:10, optimal d:7, associated test error:4.196\n",
      "run:11, optimal d:5, associated test error:3.981\n",
      "run:12, optimal d:7, associated test error:2.259\n",
      "run:13, optimal d:6, associated test error:3.443\n",
      "run:14, optimal d:7, associated test error:2.797\n",
      "run:15, optimal d:7, associated test error:3.497\n",
      "run:16, optimal d:7, associated test error:2.69\n",
      "run:17, optimal d:7, associated test error:2.743\n",
      "run:18, optimal d:7, associated test error:3.443\n",
      "run:19, optimal d:6, associated test error:3.443\n",
      "run:20, optimal d:7, associated test error:3.228\n"
     ]
    }
   ],
   "source": [
    "optimal_d = optimal_d.astype(int)\n",
    "#print(optimal_d+1) #20 optimal d value indices. Indexing starts at 0 so shifted by +1 (powers run from 1 to 7)\n",
    "optimal_d_test_errors = test_errors[range(len(optimal_d[:,0])),optimal_d[:,0]]\n",
    "for i in range(20):\n",
    "    print('run:' + str(i+1) + ', optimal d:'+str(optimal_d[i,0]+1) + ', associated test error:' + str(round(optimal_d_test_errors[i],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean optimal d with std: 6.6±0.583\n",
      "mean optimal test error with std: 3.217±0.492\n"
     ]
    }
   ],
   "source": [
    "print('mean optimal d with std: ' + str(round(np.mean(optimal_d+1),3)) + \"±\" +  str(round(np.std(optimal_d+1),3)))\n",
    "print('mean optimal test error with std: ' + str(round(np.mean(optimal_d_test_errors),3)) + \"±\" +  str(round(np.std(optimal_d_test_errors),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion matrix: Perform 20 runs : when using the 80% training data split that further to perform\n",
    "5-fold cross-validation to select the “best” parameter d\n",
    "∗\n",
    "retrain on the full “80%” training set using d\n",
    "∗\n",
    "and then produce a confusion matrix. Here the goal is to find “confusions” thus if the true label (on\n",
    "the test set) was “7” and “2” was predicted then a “error” should recorded for “(7,2)”; the final output\n",
    "will be a 10 × 10 matrix where each cell contains a confusion error rate and its standard deviation\n",
    "(here you will have averaged over the 20 runs). Note the diagonal will be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXRUNS=20\n",
    "powers=np.array([[1,2,3,4,5,6,7]])\n",
    "full_data = zipcombo.copy()\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "NUMPOWERS = powers.shape[1]\n",
    "epochs=2\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "indicesFullData = np.arange(full_data.shape[0])\n",
    "\n",
    "#in confusion matrix the row represents the true label and the column the represents the predicted label found by the perceptron\n",
    "confusionMatrix = np.zeros((MAXRUNS,10,10))\n",
    "confusionMatrixRowSums = np.zeros((MAXRUNS,10,1))\n",
    "optimal_d_test_predictions = (test_predictions_store[range(len(optimal_d[:,0])),optimal_d[:,0],:]).astype(int)\n",
    "optimal_d_train_predictions = (train_predictions_store[range(len(optimal_d[:,0])),optimal_d[:,0],:]).astype(int)\n",
    "\n",
    "for runs in range(MAXRUNS):\n",
    "    rng.shuffle(indicesFullData, axis=0)\n",
    "    splits=np.array_split(full_data[indicesFullData,:],5) #5 splits for training and testing separation\n",
    "    testing_data = splits[4] #1/5 parts or 20% as testing split\n",
    " \n",
    "    true_labels = (testing_data[:,[0]]).astype(int) #testing set labels\n",
    "    for i in range(true_labels.shape[0]):\n",
    "        #we add 1 to confusion matrix entry indexed by (true label, predicted label) for each testing label across the 20 runs\n",
    "        confusionMatrix[runs,true_labels[i,0], optimal_d_test_predictions[runs,i]] = confusionMatrix[runs,true_labels[i,0], optimal_d_test_predictions[runs,i]] + 1\n",
    "   \n",
    "    #total number of images with label 'a'  can be found by summing total number of images in row 'a' of confusion matrix. Here we haven't set the diagonal to 0 yet so when we sum we find total number of images\n",
    "    #that have true label='a'\n",
    "    confusionMatrixRowSums[runs,:,[0]] = np.sum(confusionMatrix[runs,:,:], axis=1) \n",
    "\n",
    "    np.fill_diagonal(confusionMatrix[runs,:,:],0) #diagonal needs to be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate_matrix = confusionMatrix/confusionMatrixRowSums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "error rates(in %) for OVR\n",
      "0.0000±0.0000  0.1129±0.2349  0.1991±0.2930  0.2627±0.3588  0.1282±0.1840  0.0979±0.1816  0.3870±0.4749  0.1126±0.1848  0.1795±0.2133  0.0485±0.1156  \n",
      "0.0213±0.0927  0.0000±0.0000  0.0793±0.1587  0.0593±0.1411  0.2976±0.3469  0.0611±0.1964  0.2435±0.3567  0.0401±0.1205  0.1216±0.2296  0.0793±0.1587  \n",
      "0.3238±0.4030  0.2695±0.3137  0.0000±0.0000  0.5032±0.7272  0.6440±0.5495  0.2382±0.3142  0.2378±0.3555  0.6681±0.6126  0.6648±0.7653  0.0269±0.1172  \n",
      "0.3876±0.5069  0.3671±0.5143  0.6400±0.5551  0.0000±0.0000  0.1502±0.3175  1.8889±1.3175  0.0584±0.1753  0.2202±0.3753  1.0618±0.8854  0.0627±0.1884  \n",
      "0.0291±0.1267  0.5660±0.6531  0.7487±0.5829  0.0598±0.1794  0.0000±0.0000  0.1419±0.3037  0.4931±0.4650  0.3522±0.3865  0.2867±0.3405  0.5205±0.3677  \n",
      "0.9878±0.7209  0.2076±0.3864  0.3626±0.3922  1.1616±0.8854  0.3612±0.5011  0.0000±0.0000  0.6257±0.7723  0.3105±0.4208  0.5592±0.6310  0.4745±0.6487  \n",
      "1.0085±0.5814  0.3181±0.4593  0.1208±0.3084  0.0318±0.1388  0.3249±0.3920  0.4731±0.4727  0.0000±0.0000  0.0911±0.2173  0.2375±0.3436  0.0565±0.1697  \n",
      "0.0967±0.2303  0.1884±0.2880  0.5415±0.5826  0.1646±0.2856  0.8172±0.7253  0.0954±0.2275  0.0888±0.3869  0.0000±0.0000  0.2942±0.3840  0.9142±0.8677  \n",
      "0.8812±0.7479  0.3788±0.4533  0.5926±0.6660  1.5277±1.0709  0.5580±0.6293  1.3725±1.0884  0.1375±0.4124  0.3683±0.5750  0.0000±0.0000  0.5580±0.4780  \n",
      "0.1828±0.2794  0.1241±0.2488  0.1224±0.2457  0.2153±0.3439  1.3822±1.2087  0.1846±0.2825  0.1228±0.2458  1.3587±0.8656  0.1435±0.3031  0.0000±0.0000  \n"
     ]
    }
   ],
   "source": [
    "error_rate_mean = np.mean(100*error_rate_matrix, axis=0)\n",
    "error_rate_std = np.std(100*error_rate_matrix, axis=0)\n",
    "print('error rates(in %) for OVR')\n",
    "# print('                    ', end='')\n",
    "# for i in range(10):\n",
    "#     print('predicted='+str(i),end='    ')\n",
    "# print('')\n",
    "\n",
    "for i in range(10):\n",
    "    # print('true label = '+str(i),end='      ')\n",
    "    for j in range(10):\n",
    "        print(\"%.4f\" % error_rate_mean[i,j], end='')\n",
    "        print('±', end='')\n",
    "        print(\"%.4f\" % error_rate_std[i,j], end='  ')\n",
    "    print('')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the dataset relative to your experiments there will be five hardest to predict correctly “pixelated\n",
    "images.” Print out the visualisation of these five digits along with their labels. Is it surprising that\n",
    "these are hard to predict?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAXRUNS=20\n",
    "powers=np.array([[1,2,3,4,5,6,7]])\n",
    "full_data = zipcombo.copy()\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "NUMPOWERS = powers.shape[1]\n",
    "epochs=2\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "indicesFullData = np.arange(full_data.shape[0])\n",
    "\n",
    "\n",
    "incorrectly_predicted = np.zeros((1,full_data.shape[0]))\n",
    "for runs in range(MAXRUNS):\n",
    "    rng.shuffle(indicesFullData, axis=0) #shuffled indices\n",
    "    splits=np.array_split(full_data[indicesFullData,:],5) #5 splits for training and testing separation\n",
    "    training_data = np.vstack(splits[:4]) #4/5 parts or 80% as training split\n",
    "    testing_data = splits[4] #1/5 parts or 20% as testing split\n",
    "\n",
    "    #extracting data labels for full shuffled dataset\n",
    "    true_labels = (full_data[indicesFullData,0]).astype(int)\n",
    "    \n",
    "    #concatenating training and testing predictions under optimal d values\n",
    "    optimal_predicted_labels = np.concatenate((optimal_d_train_predictions[runs,:],optimal_d_test_predictions[runs,:]),axis=0)\n",
    "\n",
    "    #adding 1 to incorrectly predicted counter array every where the prediction doesn't match the true label\n",
    "    #the data is shuffled so when adding 1 to the incorrectly predicted counter array we take this into account by splicing the counter array with the shuffled indices\n",
    "    incorrectly_predicted[:,indicesFullData] += (optimal_predicted_labels!=true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "temp = np.argsort(-incorrectly_predicted) #we reverse sort the inccorectly predicted counter array to make it into descending order\n",
    "indices_of_5_most_pixelated = temp[0,:5] #then we just take the 5 first indices of the array sorted in ascending order\n",
    "counter=1\n",
    "for i in indices_of_5_most_pixelated:\n",
    "    counter=counter+1\n",
    "    #print(i)\n",
    "    plt.imshow(np.reshape(full_data[i,1:],(16,16)), cmap='gray')\n",
    "    plt.grid(None)\n",
    "    plt.axis('off')\n",
    "    plt.title('true label: ' + str(int(full_data[i,0])))\n",
    "    plt.savefig('Q1_' + str(counter)+'.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat 1 and 2 (d∗ is now c and {1, . . . , 7} is now S) above with a Gaussian kernel $K(p,q) = e^{-c || p - q||^{2}}$ c the width of the kernel is now a parameter which must be optimised during cross-validation however, you will also need to perform some initial experiments to a decide a reasonable set S of values to crossvalidate c over.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as cd\n",
    "def Gaussian_kernel_matrix(x,y,c):\n",
    "    \"\"\" function to return the log of gaussian kernel gram matrix with parameter array c \"\"\"\n",
    "    data1 = x.copy()\n",
    "    data2 = y.copy()\n",
    "    data1 = data1[:,1:] #getting rid of label column\n",
    "    data2 = data2[:,1:] #getting rid of label column\n",
    "    #cdist allows us to compute pairwise squared euclidean distances between rows of x and rows of y\n",
    "    K = ((cd.cdist(data1, data2))**2) #I will multiply by c and exponentiate during training to reduce training costs\n",
    "\n",
    "    return K\n",
    "\n",
    "def test_one_versus_rest(test,classes,powers, alpha,testing_kernel):\n",
    "    \"\"\" testing function for one versus rest with gaussian kernel\n",
    "    inputs:\n",
    "        test: the ground truth labels of the testing data\n",
    "        classes: the possible classes of our data \n",
    "        powers: the powers that we want to pass to polynomial kernel\n",
    "        alpha: the alpha values found by the training algorithm\n",
    "        testing_kernel\n",
    "        \n",
    "        outputs:\n",
    "            \n",
    "            confidence: the (NumberOfPowers by NumberOfClasses by NumberOfDataPoints) 3D-dimensional array containing \n",
    "            the confidences of each of our 10(=NumberOfClasses) OVR classifiers trained on the training data with polynomial kernel power=d (for d=1 to NumberOfPowers) tested on a \n",
    "            test set with size=NumberOfDataPoints. \n",
    "            prediction: the (NumberOfPowers by NumberOfDataPoints) array containing the predicted label which is found by taking the confidence array and taking argmax of the confidence array across \n",
    "            second dimension of the array (ie across NumberOfClasses). This finds the indices(or labels) that maximise the confidence\n",
    "            accuracy: the (1 by NumberOfPowers) dimensional accuracies of our predictions. Found by checking the prediction array against the ground truth labels\"\"\"\n",
    "    testing_data = test.copy()\n",
    "\n",
    "\n",
    "    NumberOfClasses = classes.shape[1]\n",
    "    NumberOfDataPoints = testing_data.shape[0]\n",
    "    NumberOfPowers = powers.shape[1]\n",
    "    confidence = np.zeros((NumberOfPowers,NumberOfClasses,NumberOfDataPoints))\n",
    "    predictions = np.zeros((NumberOfPowers,NumberOfDataPoints))\n",
    "    counter = np.zeros((NumberOfPowers,NumberOfDataPoints))\n",
    "\n",
    "    for d in range(NumberOfPowers):\n",
    "        currK = np.exp(-1*powers[0,d]*testing_kernel)\n",
    "        for t in range(NumberOfDataPoints):\n",
    "            y_t = testing_data[[t],0] #receive label\n",
    "\n",
    "\n",
    "            \n",
    "            confidence[d,:,[t]] = (np.matmul(alpha[d,:,:],currK[:, [t]])).T\n",
    "            predictions[d,[t]] = np.argmax(confidence[d,:,[t]], axis=1)\n",
    "            y_hat = predictions[d,[t]]\n",
    "            \n",
    "            #if correct prediction\n",
    "            counter[d,[t]] = 1*((y_hat  == y_t))\n",
    "\n",
    "        \n",
    "    accuracy = 100*np.sum(counter,axis=1)/NumberOfDataPoints\n",
    "    return accuracy, confidence, predictions\n",
    "\n",
    "\n",
    "def train_one_versus_rest(labelsdata,classes,powers, EPOCHS,training_kernel):\n",
    "    \"\"\"\n",
    "    function to train NumberOfClasses ovr classifiers in parallel\n",
    "    INPUT\n",
    "     data: training data's original labels \n",
    "     classes: labels we want to classify the data to\n",
    "     powers: powers we're passing to our kernel function\n",
    "     EPOCHS: is the number of times we cycle through data\n",
    "     training_kernel\n",
    "\n",
    "     OUTPUT\n",
    "     alpha: the final alpha values after the training has finished\n",
    "     it is (NumberOfPowers by NumberOfClasses by NumberOfDataPoints) dimensional\n",
    "    \"\"\"\n",
    "    training_data = labelsdata.copy()\n",
    "    k_class_train = OneVersusRest(training_data,classes)\n",
    "\n",
    "\n",
    "    \n",
    "    NumberOfClasses = classes.shape[1]\n",
    "    NumberOfDataPoints = training_data.shape[0]\n",
    "    NumberOfPowers = powers.shape[1]\n",
    "    #initialise alpha vector\n",
    "    alpha = np.zeros((NumberOfPowers,NumberOfClasses,NumberOfDataPoints))\n",
    "    for epoch in range(EPOCHS):\n",
    "        for d in range(NumberOfPowers):\n",
    "\n",
    "            currK = np.exp(-1*powers[0,d]*training_kernel)#here i calculate the actual gaussian kernel values for the range of c values(widths).Doing this I don't have to store a gaussian kernel matrix for each c \n",
    "\n",
    "\n",
    "            for t in range(NumberOfDataPoints):\n",
    "                y_t = k_class_train[[t],:] #receive label\n",
    "\n",
    "\n",
    "                #prediction step\n",
    "                y_hat = np.sign(np.matmul(alpha[d,:,:],currK[:, [t]]))\n",
    "                y_hat = np.squeeze(y_hat)\n",
    "                #training step\n",
    "                alpha[d,:,t] = alpha[d,:,t] + y_t*((y_hat != y_t)) #update alpha only if prediction wrong\n",
    "\n",
    "    return alpha\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_gaussian_kernel = Gaussian_kernel_matrix(zipcombo,zipcombo,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#this code cell takes about 2 minutes to run\n",
    "#initial exploration to find c range to crossvalidate over\n",
    "MAXRUNS=5\n",
    "\n",
    "powers = np.array([[-1,-0.75, -0.5, -0.25, 0, 0.25,0.5, 0.75, 1, 1.25, 1.5, 1.75, 2]])\n",
    "\n",
    "full_data = zipcombo.copy()\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "NUMPOWERS = powers.shape[1]\n",
    "epochs=2\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "indicesFullData = np.arange(full_data.shape[0])\n",
    "\n",
    "\n",
    "initial_exploration_training_accuracies = np.zeros((MAXRUNS, NUMPOWERS))\n",
    "\n",
    "\n",
    "for runs in range(MAXRUNS):\n",
    "    print(runs)\n",
    "    rng.shuffle(indicesFullData, axis=0)\n",
    "    splits=np.array_split(labelsdata[indicesFullData,[0]],5) #5 splits for training and testing separation\n",
    "    training_data =np.array([np.hstack(splits[:4])]).T #4/5 parts or 80% as training split\n",
    "\n",
    "    indexsplit = np.array_split(indicesFullData,5)\n",
    "    indextrain = np.concatenate((indexsplit[0], indexsplit[1],indexsplit[2],indexsplit[3]))\n",
    "    training_kernel = full_gaussian_kernel[indextrain,:][:,indextrain]\n",
    "\n",
    "    \n",
    "    alpha = train_one_versus_rest(training_data,classes,powers,epochs,training_kernel) #training and returning alpha\n",
    "    training_acc, training_conf, train_predictions = test_one_versus_rest(training_data,classes,powers, alpha,training_kernel) #training accuracies\n",
    "\n",
    "\n",
    "    initial_exploration_training_accuracies[runs,:] = training_acc  #storing exploratory accuracies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracies for OVR with gaussian kernel with parameter c averaged over 5 runs:\n",
      "c=-1.0   3.250\n",
      "c=-0.75   3.186\n",
      "c=-0.5   3.159\n",
      "c=-0.25   3.111\n",
      "c=0.0   10.507\n",
      "c=0.25   99.642\n",
      "c=0.5   99.653\n",
      "c=0.75   99.629\n",
      "c=1.0   99.624\n",
      "c=1.25   99.624\n",
      "c=1.5   99.624\n",
      "c=1.75   99.626\n",
      "c=2.0   99.621\n"
     ]
    }
   ],
   "source": [
    "print('training accuracies for OVR with gaussian kernel with parameter c averaged over 5 runs:')\n",
    "\n",
    "for i in range(NUMPOWERS):\n",
    "    print('c=' + str(powers[0,i]) + \"   %.3f\" %(np.mean(initial_exploration_training_accuracies, axis=0))[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that the initial exploration training accuracies sharply increase between c=0 and c=1. To avoid the risk of overfitting, I will not investigate beyond c=1 as the training accuracy at c=1 is already quite high. Instead I will further investigate  values of c=(0.5)^n for n=0 to 15 to investigate what's happening between 0 and 1 for ever decreasing values of c."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#this cell runs for about 3 mins\n",
    "#initial exploration to find c range to crossvalidate over\n",
    "MAXRUNS=5\n",
    "\n",
    "powers = (np.array([0.5**np.arange(16)]))\n",
    "\n",
    "full_data = zipcombo.copy()\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "NUMPOWERS = powers.shape[1]\n",
    "epochs=2\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "indicesFullData = np.arange(full_data.shape[0])\n",
    "\n",
    "\n",
    "initial_exploration_training_accuracies = np.zeros((MAXRUNS, NUMPOWERS))\n",
    "\n",
    "\n",
    "for runs in range(MAXRUNS):\n",
    "    print(runs)\n",
    "    rng.shuffle(indicesFullData, axis=0)\n",
    "    splits=np.array_split(labelsdata[indicesFullData,[0]],5) #5 splits for training and testing separation\n",
    "    training_data =np.array([np.hstack(splits[:4])]).T #4/5 parts or 80% as training split\n",
    "\n",
    "    indexsplit = np.array_split(indicesFullData,5)\n",
    "    indextrain = np.concatenate((indexsplit[0], indexsplit[1],indexsplit[2],indexsplit[3]))\n",
    "    training_kernel = full_gaussian_kernel[indextrain,:][:,indextrain]\n",
    "\n",
    "    \n",
    "    alpha = train_one_versus_rest(training_data,classes,powers,epochs,training_kernel) #training and returning alpha\n",
    "    training_acc, training_conf, train_predictions = test_one_versus_rest(training_data,classes,powers, alpha,training_kernel) #training accuracies\n",
    "\n",
    "\n",
    "    initial_exploration_training_accuracies[runs,:] = training_acc  #storing exploratory accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training accuracies for OVR with gaussian kernel with parameter c averaged over 5 runs:\n",
      "index:0, c=1.0   99.624\n",
      "index:1, c=0.5   99.653\n",
      "index:2, c=0.25   99.642\n",
      "index:3, c=0.125   99.696\n",
      "index:4, c=0.0625   99.769\n",
      "index:5, c=0.03125   99.855\n",
      "index:6, c=0.015625   99.796\n",
      "index:7, c=0.0078125   99.336\n",
      "index:8, c=0.00390625   97.871\n",
      "index:9, c=0.001953125   95.454\n",
      "index:10, c=0.0009765625   92.526\n",
      "index:11, c=0.00048828125   89.622\n",
      "index:12, c=0.000244140625   82.646\n",
      "index:13, c=0.0001220703125   85.622\n",
      "index:14, c=6.103515625e-05   67.552\n",
      "index:15, c=3.0517578125e-05   59.524\n"
     ]
    }
   ],
   "source": [
    "print('training accuracies for OVR with gaussian kernel with parameter c averaged over 5 runs:')\n",
    "\n",
    "for i in range(NUMPOWERS):\n",
    "    print('index:'+ str(i)+', c=' + str(powers[0,i]) + \"   %.3f\" %(np.mean(initial_exploration_training_accuracies, axis=0))[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see we first pass the 90% accuracy threshold at index 10 and from index 10 to index 5 the accuracies are increasing. Thus I will be cross validating values of c=(0.5)^n for n=5 to 10 and this will be S."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) repeated in gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#this cell runs for about 5 minutes\n",
    "S = (np.array([0.5**np.arange(5,11)]))\n",
    "MAXRUNS=20\n",
    "\n",
    "\n",
    "full_data = zipcombo.copy()\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "NUMPOWERS = S.shape[1]\n",
    "epochs=2\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "indicesFullData = np.arange(full_data.shape[0])\n",
    "\n",
    "\n",
    "all_training_accuracies_gaussian = np.zeros((MAXRUNS, NUMPOWERS))\n",
    "all_testing_accuracies_gaussian = np.zeros((MAXRUNS, NUMPOWERS))\n",
    "\n",
    "for runs in range(MAXRUNS):\n",
    "    print(runs)\n",
    "    rng.shuffle(indicesFullData, axis=0)\n",
    "    splits=np.array_split(labelsdata[indicesFullData,[0]],5) #5 splits for training and testing separation\n",
    "    training_data =np.array([np.hstack(splits[:4])]).T #4/5 parts or 80% as training split\n",
    "    testing_data = np.array([splits[4]]).T #1/5 parts or 20% as testing split\n",
    "    indexsplit = np.array_split(indicesFullData,5)\n",
    "    indextrain = np.concatenate((indexsplit[0], indexsplit[1],indexsplit[2],indexsplit[3]))\n",
    "    indextest = indexsplit[4]\n",
    "\n",
    "\n",
    "    training_kernel = full_gaussian_kernel[indextrain,:][:,indextrain]\n",
    "    testing_kernel = full_gaussian_kernel[indextrain,:][:,indextest]\n",
    "\n",
    "    alpha = train_one_versus_rest(training_data,classes,S,epochs,training_kernel) #training and returning alpha\n",
    "    training_acc, training_conf, train_predictions = test_one_versus_rest(training_data,classes,S, alpha,training_kernel) #training accuracies\n",
    "    testing_acc, testing_conf, test_predictions = test_one_versus_rest(testing_data,classes,S, alpha,testing_kernel) #testing accuracies\n",
    "\n",
    "    all_training_accuracies_gaussian[runs,:] = training_acc  #storing accuracies\n",
    "    all_testing_accuracies_gaussian[runs,:] = testing_acc    #storing accuracies\n",
    "\n",
    "    if(runs==0):\n",
    "        test_predictions_store_gaussian = test_predictions\n",
    "        train_predictions_store_gaussian = train_predictions\n",
    "    else:\n",
    "        test_predictions_store_gaussian = np.dstack((test_predictions_store_gaussian,test_predictions))\n",
    "        train_predictions_store_gaussian = np.dstack((train_predictions_store_gaussian,train_predictions))\n",
    "\n",
    "test_predictions_store_gaussian = np.transpose(test_predictions_store_gaussian,(2,0,1))\n",
    "train_predictions_store_gaussian = np.transpose(train_predictions_store_gaussian,(2,0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c            training error(mean±std)            testing errors(mean±std)\n",
      "0.03125            0.1741±0.0695                     3.3217±0.4545\n",
      "0.015625            0.2373±0.1356                     2.9398±0.3665\n",
      "0.0078125            0.6419±0.2343                     3.5557±0.4950\n",
      "0.00390625            2.4802±0.4829                     5.0538±0.8802\n",
      "0.001953125            4.5436±0.9064                     6.4228±1.0458\n",
      "0.0009765625            7.9661±2.5635                     9.2200±2.8364\n"
     ]
    }
   ],
   "source": [
    "test_errors_gaussian  = 100 - all_testing_accuracies_gaussian\n",
    "train_errors_gaussian  = 100 - all_training_accuracies_gaussian\n",
    "\n",
    "print('c            training error(mean±std)            testing errors(mean±std)')\n",
    "for d in range(NUMPOWERS):\n",
    "    print(str(S[0,d]), end='            ')\n",
    "    print(str(\"%.4f\" % np.mean(train_errors_gaussian, axis=0)[d]) + '±' + str(\"%.4f\" % np.std(train_errors_gaussian, axis=0)[d]), end='                     ')\n",
    "    print(str(\"%.4f\" % np.mean(test_errors_gaussian, axis=0)[d]) + '±' + str(\"%.4f\" % np.std(test_errors_gaussian, axis=0)[d]))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) repeated in gaussian kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\riand\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py:102: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#this cell runs for about 16 minutes\n",
    "MAXRUNS=20\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "S = (np.array([0.5**np.arange(5,11)]))\n",
    "NUMPOWERS = powers.shape[1]\n",
    "epochs=2\n",
    "\n",
    "indicesFullData = np.arange(full_data.shape[0])\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "optimal_c_gaussian = np.zeros((MAXRUNS,1))\n",
    "\n",
    "for runs in range(MAXRUNS):\n",
    "    print(runs)\n",
    "    rng.shuffle(indicesFullData, axis=0)\n",
    "    splits=np.array_split(labelsdata[indicesFullData,[0]],5) #5 splits for training and testing separation\n",
    "    training_data =np.array([np.hstack(splits[:4])]).T #4/5 parts or 80% as training split\n",
    "\n",
    "    \n",
    "    indexsplit = np.array_split(indicesFullData,5)\n",
    "    indextrain = np.concatenate((indexsplit[0], indexsplit[1],indexsplit[2],indexsplit[3]))\n",
    "\n",
    "\n",
    "    #cross validation to find optimal d\n",
    "    cross_splits = np.array_split(training_data,5)\n",
    "    cross_splits_indices = np.array_split(indextrain,5)\n",
    "    accuracies_sum=0\n",
    "    for fold_number in range(5):\n",
    "        training_folds = np.vstack(np.delete(cross_splits, fold_number))\n",
    "        training_folds_indices = np.hstack(np.delete(cross_splits_indices, fold_number))\n",
    "        training_kernel = full_gaussian_kernel[training_folds_indices,:][:,training_folds_indices]\n",
    "\n",
    "\n",
    "        alpha = train_one_versus_rest(training_folds,classes,S,epochs,training_kernel) #training and returning alpha\n",
    "        training_acc, training_conf, train_predictions = test_one_versus_rest(training_folds,classes,S, alpha,training_kernel) #training accuracies\n",
    "        accuracies_sum = accuracies_sum + training_acc\n",
    "    optimal_c_gaussian[runs,0] = np.argmax(accuracies_sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run:1, optimal c:0.03125, associated test error:2.743\n",
      "run:2, optimal c:0.03125, associated test error:3.281\n",
      "run:3, optimal c:0.015625, associated test error:2.797\n",
      "run:4, optimal c:0.03125, associated test error:3.55\n",
      "run:5, optimal c:0.03125, associated test error:3.281\n",
      "run:6, optimal c:0.03125, associated test error:3.066\n",
      "run:7, optimal c:0.03125, associated test error:3.819\n",
      "run:8, optimal c:0.03125, associated test error:3.712\n",
      "run:9, optimal c:0.03125, associated test error:2.905\n",
      "run:10, optimal c:0.03125, associated test error:3.604\n",
      "run:11, optimal c:0.03125, associated test error:3.281\n",
      "run:12, optimal c:0.015625, associated test error:2.259\n",
      "run:13, optimal c:0.03125, associated test error:4.034\n",
      "run:14, optimal c:0.03125, associated test error:2.743\n",
      "run:15, optimal c:0.03125, associated test error:3.55\n",
      "run:16, optimal c:0.03125, associated test error:2.69\n",
      "run:17, optimal c:0.03125, associated test error:2.743\n",
      "run:18, optimal c:0.03125, associated test error:4.088\n",
      "run:19, optimal c:0.03125, associated test error:3.765\n",
      "run:20, optimal c:0.03125, associated test error:3.497\n"
     ]
    }
   ],
   "source": [
    "optimal_c_gaussian = optimal_c_gaussian.astype(int)\n",
    "optimal_c_gaussian_test_errors = test_errors_gaussian[range(len(optimal_c_gaussian[:,0])),optimal_c_gaussian[:,0]]\n",
    "for i in range(20):\n",
    "    print('run:' + str(i+1) + ', optimal c:'+str(S[0,optimal_c_gaussian[i,0]]) + ', associated test error:' + str(round(optimal_c_gaussian_test_errors[i],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean optimal c with std: 0.03±0.005\n",
      "mean optimal test error with std: 3.271±0.495\n"
     ]
    }
   ],
   "source": [
    "print('mean optimal c with std: ' + str(round(np.mean(S[:,optimal_c_gaussian]),3)) + \"±\" +  str(round(np.std(S[:,optimal_c_gaussian]),3)))\n",
    "print('mean optimal test error with std: ' + str(round(np.mean(optimal_c_gaussian_test_errors),3)) + \"±\" +  str(round(np.std(optimal_c_gaussian_test_errors),3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Choose (research) an alternate method to generalise the kernel perceptron to k-classes then repeat 1\n",
    "and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OneVersusOne(label, i,j):\n",
    "    \"\"\" function to transform label in one verus one form \"\"\"\n",
    "    return int(label==i) - int(label==j)\n",
    "\n",
    "def filter_indices(labels,indices,i,j):\n",
    "    \"\"\" function to filter an array of indices keeping only the indices that have labels i and j \"\"\"\n",
    "    return np.intersect1d(np.where(labelsdata==[i,j])[0], indices)\n",
    "\n",
    "def Poly_kernel_matrix(x,y,d):\n",
    "    \"\"\" function to compute gram matrix for polynomial kernel with power d=1. Using the first power we can then iteratively multiply the gram matrix with itself to build higher powers of it. \"\"\"\n",
    "    data1 = x.copy()\n",
    "    data2 = y.copy()\n",
    "    data1 = data1[:,1:] #getting rid of label column\n",
    "    data2 = data2[:,1:] #getting rid of label column\n",
    "    K = (data1@ np.transpose(data2))\n",
    "    return K\n",
    "\n",
    "\n",
    "def test_one_versus_one(all_labels,classes,powers,training_indices,testing_indices,BigAlpha,fullkernelmatrix):\n",
    "    \"\"\" testing function for one versus one with polynomial kernel\n",
    "    inputs:\n",
    "        all_labels: the ground truth labels of the testing data\n",
    "        classes: the possible classes of our data \n",
    "        powers: the powers that we want to pass to polynomial kernel\n",
    "        training_indices: the indices of the data corresponding to training set. Used to extract the right rows of kernel matrix\n",
    "        testing_indices: the indices of the data corresponding to testing set. Used to extract the right columns of kernel matrix\n",
    "        BigAlpha: the alpha values found by the training algorithm\n",
    "        fullkernelmatrixx: the gram matrix calculated for the whole dataset. by calculating it once and extracting what we need we save some time\n",
    "        \n",
    "        outputs:\n",
    "            \n",
    "            confidence: the (NumberOfPowers by NumberOfClasses by NumberOfDataPoints) 3D-dimensional array containing \n",
    "            the confidences of each of our 10(=NumberOfClasses) OVR classifiers trained on the training data with polynomial kernel power=d (for d=1 to NumberOfPowers) tested on a \n",
    "            test set with size=NumberOfDataPoints. \n",
    "            predictions: the (NumberOfPowers  by NumberOfDataPoints) array containing the predicted label which is found by taking the SUM of all the confidences of classsifiers related to digit i \n",
    "            (this gives a NumberOfPowers by NUMCLASSES by NumberOfTestPoints) and taking argmax of this sum of confidence array across the second dimension.This finds the indices(or labels) that maximise the confidence\n",
    "            accuracy: the (1 by NumberOfPowers) dimensional accuracies of our predictions. Found by checking the prediction array against the ground truth labels\"\"\"\n",
    "    NUMCLASSES = classes.shape[1]\n",
    "    NumberOfPowers = powers.shape[1]\n",
    "    counter=0 #this counter will keep track of which of the 45 classifiers we're currently on\n",
    "\n",
    "    index_list_testing = testing_indices\n",
    "    NumberOfTestPoints = index_list_testing.shape[0]\n",
    "    all_confidences = np.zeros((NumberOfPowers,NUMCLASSES,NUMCLASSES, NumberOfTestPoints))\n",
    "    \n",
    "    #for loops to cycle through possible 2 digit combinations\n",
    "    for i in range(NUMCLASSES):\n",
    "        for j in range(i+1,NUMCLASSES):\n",
    "            if(i==j): #not interested in training OVA for i=j as we'd be training on one class whereas OVO requires two\n",
    "                continue\n",
    "            index_list_training = filter_indices(all_labels,training_indices,i,j) #keep only the data that has the labels we're interested in\n",
    "\n",
    "            testing_ker = fullkernelmatrix[index_list_training,:][:,index_list_testing] #extract corresponding kernel values\n",
    "\n",
    "            curr_ker=1\n",
    "            confidence = np.empty((NumberOfPowers,NumberOfTestPoints))\n",
    "            for d in range(NumberOfPowers):\n",
    "                curr_ker = curr_ker*testing_ker #iteratively multiply the kernel matrix with itself to go through the range of powers\n",
    "                confidence = ((BigAlpha[counter])[d,:])@curr_ker #remember counter keeeps track of which classifier we're on\n",
    "                \n",
    "                #since training to distinguish digits i and j is the same as distinguishing labels j and i (just with the +1, -1 OVO labels reversed). We can use this fact to compute the confidence of\n",
    "                #classfier h(j,i) as the negative of the confidence of classifier h(i,j)\n",
    "                all_confidences[d,i,j,:] = confidence\n",
    "                all_confidences[d,j,i,:] = -1*confidence\n",
    "            counter=counter+1\n",
    "\n",
    "    #we sum all the confidences of classifiers that have been trained to distinguish digit i and then find the argmax of all these summed confidences\n",
    "    predictions = np.argmax(np.sum(all_confidences, axis=2), axis=1)\n",
    "    accuracies = 100*np.mean(predictions==np.squeeze(all_labels[testing_indices]),axis=1)\n",
    "    return predictions,accuracies\n",
    "\n",
    "def train_one_versus_one(all_labels,classes,powers, EPOCHS,training_indices,fullkernelmatrix):\n",
    "    \"\"\" training function for one versus one with polynomial kernel\n",
    "    inputs:\n",
    "        all_labels: the ground truth labels of the training data\n",
    "        classes: the possible classes of our data \n",
    "        powers: the powers that we want to pass to polynomial kernel\n",
    "        training_indices: the indices of the data corresponding to training set. Used to extract the right rows of kernel matrix\n",
    "        fullkernelmatrixx: the gram matrix calculated for the whole dataset. by calculating it once and extracting what we need we save some time\n",
    "        \n",
    "        outputs:\n",
    "            \n",
    "            BigAlpha: the alpha values found by the training algorithm. It contains 45 individual (NumberOfPowers by NumberOfDataPoints) arrays, one for each classifier.\"\"\"\n",
    "\n",
    "    NUMCLASSES = classes.shape[1]\n",
    "    NumberOfPowers = powers.shape[1]\n",
    "    BigAlpha = []\n",
    "\n",
    "    for i in range(NUMCLASSES):\n",
    "        for j in range(i+1,NUMCLASSES):\n",
    "            if(i==j): #not interested in training OVA for i=j as we'd be training on one class whereas OVA requires two\n",
    "                continue\n",
    "            index_list = filter_indices(all_labels,training_indices,i,j)\n",
    "            training_ker = fullkernelmatrix[index_list,:][:,index_list]\n",
    "            NumberOfDataPoints = index_list.shape[0]\n",
    "            alpha = np.zeros((NumberOfPowers, NumberOfDataPoints))\n",
    "            for epochs in range(EPOCHS):\n",
    "                curr_ker=1\n",
    "                for d in range(NumberOfPowers):\n",
    "                    curr_ker = curr_ker*training_ker\n",
    "                    for t in range(NumberOfDataPoints):\n",
    "                        y_t = OneVersusOne(all_labels[index_list[t],:],i,j) #receive label and transform to OVO form\n",
    "                        #prediction step\n",
    "                        y_hat = np.sign(alpha[d,:]@curr_ker[:, [t]])\n",
    "                        #training step\n",
    "                        if(y_t!=y_hat):\n",
    "                            alpha[d,t] = alpha[d,t] + y_t #update alpha only if prediction wrong)\n",
    "            BigAlpha.append(alpha)     \n",
    "    return BigAlpha"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) repeated with alternative method (Basic Results: Perform 20 runs for d = 1, . . . , 7 each run should randomly split zipcombo into 80%\n",
    "train and 20% test. Report the mean test and train error rates as well as well as standard deviations.\n",
    "Thus your data table, here, will be 2 × 7 with each “cell” containing a mean±std.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_ker_poly  = Poly_kernel_matrix(zipcombo,zipcombo,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#this cell runs for about 13 minutes\n",
    "MAXRUNS=20\n",
    "powers=np.array([[1,2,3,4,5,6,7]])\n",
    "labelsdata = full_data[:,[0]]\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "NUMPOWERS = powers.shape[1]\n",
    "epochs=2\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "indicesFullData = np.arange(full_data.shape[0])\n",
    "all_training_accuracies_ovo = np.zeros((MAXRUNS, NUMPOWERS))\n",
    "all_testing_accuracies_ovo = np.zeros((MAXRUNS, NUMPOWERS))\n",
    "\n",
    "for runs in range(MAXRUNS):\n",
    "    print(runs)\n",
    "    rng.shuffle(indicesFullData, axis=0)\n",
    "\n",
    "    indexsplit = np.array_split(indicesFullData,5)\n",
    "    indextrain = np.concatenate((indexsplit[0], indexsplit[1],indexsplit[2],indexsplit[3]))\n",
    "    indextest = indexsplit[4]\n",
    "\n",
    "    BigAlpha=train_one_versus_one(labelsdata,classes,powers,epochs,indextrain,full_ker_poly) #training and returning alphas\n",
    "    test_predictions,test_accuracies = test_one_versus_one(labelsdata,classes,powers,indextrain,indextest,BigAlpha,full_ker_poly)\n",
    "    train_predictions,train_accuracies = test_one_versus_one(labelsdata,classes,powers,indextrain,indextrain,BigAlpha,full_ker_poly)\n",
    "    all_training_accuracies_ovo[runs,:] = train_accuracies  #storing accuracies\n",
    "    all_testing_accuracies_ovo[runs,:] = test_accuracies    #storing accuracies\n",
    "\n",
    "    if(runs==0):\n",
    "        test_predictions_store_ovo = test_predictions\n",
    "        train_predictions_store_ovo = train_predictions\n",
    "    else:\n",
    "        test_predictions_store_ovo = np.dstack((test_predictions_store_ovo,test_predictions))\n",
    "        train_predictions_store_ovo= np.dstack((train_predictions_store_ovo,train_predictions))\n",
    "\n",
    "test_predictions_store_ovo = np.transpose(test_predictions_store_ovo,(2,0,1))\n",
    "train_predictions_store_ovo = np.transpose(train_predictions_store_ovo,(2,0,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>ONE VERSUS ONE multiclass prediction<<<\n",
      "training errors(mean±std):\n",
      "14.64±1.62       4.56±0.66       2.33±0.25       1.39±0.16       1.02±0.14       0.81±0.13       0.67±0.12       \n",
      "testing errors(mean±std):\n",
      "15.28±1.94     6.58±0.79     4.8±0.59     4.13±0.48     3.82±0.46     3.67±0.46     3.49±0.45     "
     ]
    }
   ],
   "source": [
    "test_errors_ovo  = 100 - all_testing_accuracies_ovo\n",
    "train_errors_ovo  = 100 - all_training_accuracies_ovo\n",
    "print('>>>ONE VERSUS ONE multiclass prediction<<<')\n",
    "print('training errors(mean±std):')\n",
    "for d in range(NUMPOWERS):\n",
    "    print(str(round(np.mean(train_errors_ovo, axis=0)[d],2)) + \"±\" +  str(round(np.std(train_errors_ovo, axis=0)[d],2)),  end='       ')\n",
    "print('\\ntesting errors(mean±std):')\n",
    "for d in range(NUMPOWERS):\n",
    "    print(str(round(np.mean(test_errors_ovo, axis=0)[d],2)) + \"±\" +  str(round(np.std(test_errors_ovo, axis=0)[d],2)),  end='     ')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) repeated with alternative method( Cross-validation: Perform 20 runs : when using the 80% training data split from within to perform\n",
    "5-fold cross-validation to select the “best” parameter d\n",
    "∗\n",
    "then retrain on full 80% training set using\n",
    "d\n",
    "∗ and then record the test errors on the remaining 20%. Thus you will find 20 d\n",
    "∗ and 20 test errors.\n",
    "Your final result will consist of a mean test error±std and a mean d\n",
    "∗ with std.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "#this cell runs for about 44 minutes\n",
    "MAXRUNS=20\n",
    "classes = np.array([[0,1,2,3,4,5,6,7,8,9]])\n",
    "powers=np.array([[1,2,3,4,5,6,7]])\n",
    "NUMPOWERS = powers.shape[1]\n",
    "epochs=2\n",
    "indicesFullData = np.arange(full_data.shape[0])\n",
    "rng = np.random.default_rng(seed=7) #rng for shuffling data\n",
    "optimal_d_ovo = np.zeros((MAXRUNS,1))\n",
    "\n",
    "for runs in range(MAXRUNS):\n",
    "    print(runs)\n",
    "    rng.shuffle(indicesFullData, axis=0)\n",
    "\n",
    "    \n",
    "    indexsplit = np.array_split(indicesFullData,5)\n",
    "    indextrain = np.concatenate((indexsplit[0], indexsplit[1],indexsplit[2],indexsplit[3]))\n",
    "\n",
    "\n",
    "    #cross validation to find optimal d\n",
    "\n",
    "    cross_splits_indices = np.array_split(indextrain,5)\n",
    "    accuracies_sum=0\n",
    "    for fold_number in range(5):\n",
    "        training_folds_indices = np.hstack(np.delete(cross_splits_indices, fold_number))\n",
    "\n",
    "\n",
    "        BigAlpha=train_one_versus_one(labelsdata,classes,powers,epochs,training_folds_indices,full_ker_poly) #training and returning alphas\n",
    "        train_predictions,train_accuracies = test_one_versus_one(labelsdata,classes,powers,training_folds_indices,training_folds_indices,BigAlpha,full_ker_poly)\n",
    "        accuracies_sum = accuracies_sum + train_accuracies\n",
    "    optimal_d_ovo[runs,0] = np.argmax(accuracies_sum, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run:1, optimal d:7, associated test error:3.228\n",
      "run:2, optimal d:7, associated test error:3.55\n",
      "run:3, optimal d:7, associated test error:2.797\n",
      "run:4, optimal d:6, associated test error:3.335\n",
      "run:5, optimal d:7, associated test error:3.228\n",
      "run:6, optimal d:7, associated test error:2.905\n",
      "run:7, optimal d:7, associated test error:3.012\n",
      "run:8, optimal d:7, associated test error:3.335\n",
      "run:9, optimal d:7, associated test error:2.636\n",
      "run:10, optimal d:7, associated test error:4.196\n",
      "run:11, optimal d:7, associated test error:3.335\n",
      "run:12, optimal d:6, associated test error:2.797\n",
      "run:13, optimal d:7, associated test error:3.389\n",
      "run:14, optimal d:7, associated test error:2.797\n",
      "run:15, optimal d:7, associated test error:3.497\n",
      "run:16, optimal d:7, associated test error:2.69\n",
      "run:17, optimal d:7, associated test error:2.743\n",
      "run:18, optimal d:7, associated test error:3.443\n",
      "run:19, optimal d:7, associated test error:3.712\n",
      "run:20, optimal d:7, associated test error:3.228\n"
     ]
    }
   ],
   "source": [
    "optimal_d_ovo = optimal_d_ovo.astype(int)\n",
    "#print(optimal_d+1) #20 optimal d value indices. Indexing starts at 0 so shifted by +1 (powers run from 1 to 7)\n",
    "optimal_d_ovo_test_errors = test_errors[range(len(optimal_d_ovo[:,0])),optimal_d_ovo[:,0]]\n",
    "for i in range(20):\n",
    "    print('run:' + str(i+1) + ', optimal d:'+str(optimal_d_ovo[i,0]+1) + ', associated test error:' + str(round(optimal_d_ovo_test_errors[i],3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean optimal d with std: 6.9±0.3\n",
      "mean optimal test error with std: 3.193±0.388\n"
     ]
    }
   ],
   "source": [
    "print('mean optimal d with std: ' + str(round(np.mean(optimal_d_ovo+1),3)) + \"±\" +  str(round(np.std(optimal_d_ovo+1),3)))\n",
    "print('mean optimal test error with std: ' + str(round(np.mean(optimal_d_ovo_test_errors),3)) + \"±\" +  str(round(np.std(optimal_d_ovo_test_errors),3)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3dd5ba0fcdb24de16818bfb70fb7995edac6a09e5545214c1bd690016a414ed1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
